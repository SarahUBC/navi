---
title: "Value_statements"
author: "Sarah Klain"
date: "October 21, 2015"
output: 
  html_document: 
    keep_md: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Setup

```{r}
library(Hmisc) #to run correlations with sig levels
library(ggplot2) # for great charts
library(ggthemes) # for pretty themes in ggplot
library(viridis) # for pretty colors
library(dplyr)
library(knitr) # tool for making nice tables
library(tidyr) # data table wrangling tool
library(broom)
library(stargazer) # makes pretty tables
# library(stats) # for PCA
# library(psych)
```

Input data
```{r}
setwd("/Users/sarahklain/Documents/R_2015/navi") #set working directory
ev <- read.csv("Env_Val_02_29_2016.csv")
```

str(ev)
head(ev)

```{r}
evl <- tidyr::gather(ev, "val_state", "response", 3:33) #short form to long form data for ease in analysis

#bring into dplyr for ease in extracting one sub population
evtab <- evl %>%
  tbl_df

# str(evl)
# head(evl)
View(evtab)
```

Add new column to group data by env value type

```{r}
ev_nep <- evtab %>% 
  filter(val_state == "abuse_nep" | val_state == "bal_r_nep" | val_state == "crisis_r_nep" | val_state == "spaceship_nep" | val_state == "bau_nep") %>% 
  mutate(v_type = "NEP")

ev_inst <- evtab %>% 
  filter(val_state == "extract_r_ins" | val_state == "clean_inst" | val_state == "loss_r_ins") %>% 
  mutate(v_type = "inst")

ev_rel <- evtab %>% 
  filter(val_state == "comm_rel" | val_state == "iden_rel" | val_state == "kin_rel" | val_state == "wild_rel" | val_state == "health_rel2" | val_state == "other_rel" ) %>% 
  mutate(v_type = "rel")

ev_met <- evtab %>% 
  filter(val_state == "kin_met" | val_state == "resp_met" | val_state == "iden_met" | val_state == "other_met") %>% 
  mutate(v_type = "met")

ev_mor <- evtab %>% 
  filter(val_state == "decade_r_mor" | val_state == "right_r_mor") %>% 
  mutate(v_type = "moral")

# View(ev_met)
eval_t2 <- bind_rows(ev_nep, ev_inst, ev_rel, ev_met, ev_mor)
str(eval_t2)
summary(eval_t2)

eval_t3 <- eval_t2 %>% 
  filter(response > 0)
```


Bar plot, all value statements, MT only

```{r}
eval_t4 <- eval_t3 %>% 
  filter(sub_pop == "M-Turk")

#Histogram of 5 types of statements
# I need to nomarlize by the number of questions per type of statement
bar_type <- ggplot(eval_t4, aes(x = response, fill = v_type)) +
  geom_histogram(binwidth = 0.5) +
  scale_fill_viridis(discrete=TRUE, option = "viridis") +
  xlab("Response\n1=strongly disagree; 5=strongly agree") +
  ggtitle("To what extent do you agree with these statements?") +
  coord_cartesian(xlim = c(1, 5)) +
  facet_grid(~ v_type)

bar_type
```

```{r}
eval_t4$val_state <- factor(eval_t4$val_state, levels=c("extract_r_ins" ,"loss_r_ins","clean_inst","kin_met", "resp_met", "iden_met","other_met", "decade_r_mor","right_r_mor", "abuse_nep", "bal_r_nep", "crisis_r_nep", "spaceship_nep", "bau_nep", "comm_rel", "wild_rel", "iden_rel", "kin_rel", "health_rel2", "other_rel"))

bar_all <- ggplot(eval_t4, aes(x = response, fill = v_type)) +
  geom_histogram(binwidth = 0.5) +
  scale_fill_viridis(discrete=TRUE, option = "viridis") +
  xlab("Response\n1 = Strongly Disagree; 2 = Disagree; 3 = Neither Agree nor Disagree;\n4 = Agree; 5 = Strongly Agree") +
  ggtitle("To what extent do you agree with these statements?") +
  coord_cartesian(xlim = c(1, 5)) +
  facet_grid(~ val_state)

bar_all
#ggsave(bar_all, file="/Users/sarahklain/Documents/R_2015/env_val/figs/bar_all.pdf")
```
 
### All statements, violin plot with mean

```{r}

val_st_vio <- ggplot(eval_t4, aes(x = val_state, y = response, fill = v_type)) +
 geom_violin(adjust=0.3) +
  xlab("Statement") + ylab("Response\n1= stongly disagree; 5 = strongly agree") +
  scale_fill_viridis(discrete=TRUE, "Category of Value\nStatement") +
  ggtitle("To what extent do you agree with these value statements?") +
  coord_cartesian(ylim = c(1, 5)) +
  stat_summary(fun.y=mean, colour="orangered", geom="point", 
               shape=18, size=2)  

val_st_vio
```



```{r}
# Tried to get labeling of means with 2 decimal points. Needs more work. 
# means <- aggregate(response ~ val_state, eval_t4, mean)
# means2 = transform(summarise(group_by(eval_t4, val_state), label = mean(response)), 
 #  Label = sprintf("%.02f", label))

val_st_box <- ggplot(eval_t4, aes(x = val_state, y = response, fill = v_type)) +
 geom_boxplot() +
  xlab("Statement") + ylab("Response\n1= stongly disagree; 5 = strongly agree") +
  scale_fill_viridis(discrete=TRUE, "Category of Value\nStatement") +
  ggtitle("To what extent do you agree with these value statements?") +
  coord_cartesian(ylim = c(1, 5)) +
  stat_summary(fun.y=mean, colour="grey", geom="point", 
               shape=18, size=3)  

  #geom_text(data = means2, aes(label = Label, x = label, y = 0),  size=10)
  #stat_summary(fun.y=mean, colour="darkred", geom="point", 
   #            shape=18, size=3,show_guide = FALSE) 
  #geom_text(data = means, aes(label = response, y = response + 0.08))

val_st_box
```

T-tests to determine differences
```{r}
#find means and SD
evt_s <- ev %>%
  tbl_df

evt_s_mt <- evt_s %>%
  filter(sub_pop == "M-Turk")

# paired t-test
# t.test(y1,y2,paired=TRUE) # where y1 & y2 are numeric
head(evt_s_mt)

t.test(evt_s_mt$right_r_mor, evt_s_mt$wild_rel, paired = TRUE)
t.test(evt_s_mt$spaceship_nep, evt_s_mt$wild_rel, paired = TRUE)
t.test(evt_s_mt$wild_rel, evt_s_mt$iden_rel, paired = TRUE)
t.test(evt_s_mt$wild_rel, evt_s_mt$health_rel2, paired = TRUE)
```

```{r}
# Ward Hierarchical Clustering
# hc = hclust(dist(evt_s_mt[3:33]))
# plot(hc)

hc = hclust(dist(mtcars))
plot(hc)

# hc = hclust(dist(eval_t4[3:4]))
# plot(hc)
```


### PCA
see PCA script

```{r}
# apply PCA - scale. = TRUE is highly 
# advisable, but default is FALSE. 
# ir.pca <- prcomp(log.ir,
#                 center = TRUE,
#                scale. = TRUE) 

ev.pca <- prcomp(as.matrix(ev[3:33]), na.action = na.omit, center = TRUE, scale = TRUE) 

prcomp(na.omit(as.matrix(ev[3:33])), scale=TRUE)
prcomp(na.omit(ev[3:33]), scale=TRUE) 

ev.pca

# Pricipal Components Analysis
# entering raw data and extracting PCs 
# from the correlation matrix 
# fit <- princomp(mydata, cor=TRUE)
# summary(fit) # print variance accounted for 
# loadings(fit) # pc loadings 
# plot(fit,type="lines") # scree plot 
# fit$scores # the principal components
# biplot(fit)


fit <- princomp(na.omit(ev[3:33]), cor=TRUE)

princomp(na.omit(ev), cor = TRUE)

summary(fit) # print variance accounted for 
loadings(fit) # pc loadings 
plot(fit,type="lines") # scree plot 
fit$scores # the principal components
biplot(fit)
```


### Cronbach's alpha, see Cronbach Alpha script

```{r}
# Apply to NEP scores
nep <- read.csv("nep.csv")
alpha(nep)

# Apply to M-Turk, all variables
mt <- read.csv("env_val_MT.csv")
alpha(mt)
# alpha(met[3:7])

mt_nep <- (mt[3:7]) # only NEP values
# alpha(mt_nep)
alpha(mt_nep, check.keys=TRUE)

mt_val <- (mt[3:21]) # includes all value prompts
alpha(mt_val, check.keys = TRUE)
```

